{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This tutorial is to design and test a CNN on MNIST dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.autograd import Variable\n",
    "import torch.utils.data as Data\n",
    "import torchvision\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torch._C.Generator at 0x7f9df5b9fa10>"
      ]
     },
     "execution_count": 100,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.manual_seed(1) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hyper Parameters\n",
    "EPOCH = 1               # train the training data n times, to save time, we just train 1 epoch\n",
    "BATCH_SIZE = 32\n",
    "LR = 0.001              # learning rate\n",
    "DOWNLOAD_MNIST = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Mnist digits dataset\n",
    "train_data = torchvision.datasets.MNIST(\n",
    "    root='./mnist/',\n",
    "    train=True,                                     # this is training data\n",
    "    transform=torchvision.transforms.ToTensor(),    # Converts a PIL.Image or numpy.ndarray to\n",
    "                                                    # torch.FloatTensor of shape (C x H x W) and normalize in the range [0.0, 1.0]\n",
    "    download=DOWNLOAD_MNIST,                        # download it if you don't have it\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([60000, 28, 28])\n",
      "torch.Size([60000])\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# plot one example\n",
    "print(train_data.train_data.size())                 # (60000, 28, 28)\n",
    "print(train_data.train_labels.size())               # (60000)\n",
    "plt.imshow(train_data.train_data[1].numpy(), cmap='gray')\n",
    "plt.title('%i' % train_data.train_labels[1])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader = Data.DataLoader(dataset=train_data, batch_size=BATCH_SIZE, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert test data into Variable, pick 2000 samples to speed up testing\n",
    "test_data = torchvision.datasets.MNIST(root='./mnist/', train=False)\n",
    "test_x = Variable(torch.unsqueeze(test_data.test_data, dim=1)).type(torch.FloatTensor)[:2000]/255.   # shape from (2000, 28, 28) to (2000, 1, 28, 28), value in range(0,1)\n",
    "test_y = test_data.test_labels[:2000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [],
   "source": [
    "class NeuralNet(nn.Module):\n",
    "    def __init__(self, num_classes):\n",
    "        super(NeuralNet, self).__init__()\n",
    "        self.conv1 = nn.Sequential(\n",
    "                                      nn.Conv2d(in_channels=1, out_channels=16, kernel_size=5, stride=1, padding=2),\n",
    "                                      nn.ReLU(),\n",
    "                                      nn.MaxPool2d(kernel_size=2)\n",
    "                                  )\n",
    "        self.conv2 = nn.Sequential(\n",
    "                                      nn.Conv2d(in_channels=16, out_channels=32, kernel_size=5, stride=1, padding=2),\n",
    "                                      nn.ReLU(),\n",
    "                                      nn.MaxPool2d(kernel_size=2)\n",
    "                                  )\n",
    "        self.out = nn.Linear(32 * 7 * 7, num_classes)\n",
    "        \n",
    "    def forward(self,x):\n",
    "        x = self.conv1(x)\n",
    "        x = self.conv2(x)\n",
    "        x = x.view(x.size(0), -1)\n",
    "        x = self.out(x)\n",
    "        return x\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NeuralNet(\n",
      "  (conv1): Sequential(\n",
      "    (0): Conv2d(1, 16, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2))\n",
      "    (1): ReLU()\n",
      "    (2): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "  )\n",
      "  (conv2): Sequential(\n",
      "    (0): Conv2d(16, 32, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2))\n",
      "    (1): ReLU()\n",
      "    (2): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "  )\n",
      "  (out): Linear(in_features=1568, out_features=10, bias=True)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "net = NeuralNet(num_classes=10)\n",
    "print(net)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer =torch.optim.Adam(params=net.parameters(), lr=LR)\n",
    "loss_fn = torch.nn.CrossEntropyLoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 0 Test Accuracy: 0.986\n"
     ]
    }
   ],
   "source": [
    "for e in range(EPOCH):\n",
    "    for step, (x, y) in enumerate(train_loader): \n",
    "        x_var = Variable(x)\n",
    "        y_var = Variable(y)\n",
    "        y_pred = net(x_var)\n",
    "        loss = loss_fn(y_pred, y_var)\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "    #if e % 10 == 0:\n",
    "    test_op = net(test_x)\n",
    "    predictions = torch.max(test_op, 1)[1].data.squeeze()\n",
    "    accuracy = (predictions == test_y).sum().item() / float(test_y.size(0))\n",
    "    print(\"epoch: \" + str(e) + \" Test Accuracy: \" + str(accuracy))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Outputs\n",
      "tensor([ 7,  2,  1,  0,  4,  1,  4,  9,  5,  9])\n",
      "Predicted Outputs\n",
      "tensor([ 7,  2,  1,  0,  4,  1,  4,  9,  5,  9])\n"
     ]
    }
   ],
   "source": [
    "# Print few outputs from the test dataset\n",
    "print(\"Test Outputs\")\n",
    "print(test_y[:10])\n",
    "print(\"Predicted Outputs\")\n",
    "test_op = net(test_x[:10])\n",
    "predictions = torch.max(test_op, 1)[1].data.squeeze()\n",
    "print(predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
